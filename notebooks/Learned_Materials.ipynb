{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acdc34f1",
   "metadata": {},
   "source": [
    "# Experiments with Measured Data - Learned Materials\n",
    "\n",
    "This notebooks trains the \"Learned Materials\" of Section IV-C of the paper [\"Learning Radio Environments by\n",
    "Differentiable Ray Tracing\"](https://github.com/NVlabs/diff-rt-calibration) by J. Hoydis, F. Ait Aoudia, S. Cammerer, F. Euchner, M. Nimier-David, S. ten Brink, and A. Keller, Dec. 2023.\n",
    "\n",
    "The code is made available under the [NVIDIA License](https://github.com/NVlabs/diff-rt-calibration/blob/main/LICENSE.txt).\n",
    "\n",
    "To run this notebook, you need first to:\n",
    "\n",
    "- Download the \"dichasus-dc01.tfrecords\" file from the [DICHASUS website](https://dichasus.inue.uni-stuttgart.de/datasets/data/dichasus-dcxx/) to the folder `data/tfrecords` within the cloned repository. More information about the DICHASUS channel sounder can be found [here](https://arxiv.org/abs/2206.15302).\n",
    "\n",
    "- Create a dataset of traced paths using the script [gen_dataset.py](../code/gen_dataset.py). For this purpose, ensure that you are in the `code/` folder, and run:\n",
    "```bash\n",
    "python gen_dataset.py -traced_paths_dataset dichasus-dc01 -traced_paths_dataset_size 10000\n",
    "```\n",
    "This script stores the generated dataset in the `data/traced_paths/` folder.\n",
    "Generating the dataset of traced paths can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77eb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gpu_num = 0 # Use \"\" to use the CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e) \n",
    "tf.get_logger().setLevel('ERROR')\n",
    "            \n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append('../code')\n",
    "\n",
    "import sionna\n",
    "from utils import *\n",
    "import datetime # For logging\n",
    "from trainable_materials import  TrainableMaterials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_name = \"learned_materials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0292ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \n",
    "dataset_name = '../data/traced_paths/dichasus-dc01'\n",
    "dataset_filename = os.path.join(dataset_name + '.tfrecords')\n",
    "params_filename = os.path.join(dataset_name + '.json')\n",
    "\n",
    "# Configure training parameters and step\n",
    "batch_size = 8\n",
    "learning_rate = 1e-3\n",
    "num_iterations = 10000\n",
    "delta = 0.999 # Parameter for exponential moving average\n",
    "\n",
    "# Size of validation set size\n",
    "# The validation set is used for early stopping, to ensure\n",
    "# training does not overfit.\n",
    "validation_set_size = 100\n",
    "# We don't use the test set here, but need is size for splitting\n",
    "test_set_size = 4900\n",
    "\n",
    "# Sizes of the training set to evaluate\n",
    "training_set_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(params_filename, 'r') as openfile:\n",
    "    params = json.load(openfile)\n",
    "\n",
    "# Scene\n",
    "scene_name = params['scene_name']\n",
    "# Size of the dataset\n",
    "dataset_size = params['traced_paths_dataset_size']\n",
    "\n",
    "num_subcarriers = 1024\n",
    "bandwidth = 50e6\n",
    "frequencies = subcarrier_frequencies(num_subcarriers, bandwidth/num_subcarriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f109ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TF records as a dataset\n",
    "dataset = tf.data.TFRecordDataset([dataset_filename]).map(deserialize_paths_as_tensor_dicts)\n",
    "\n",
    "# Split the dataset\n",
    "# We don't use the test set\n",
    "training_set, validation_set, _ = split_dataset(dataset, dataset_size, training_set_size, validation_set_size, test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dcbb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    # Training set\n",
    "    training_set_iter = iter(training_set.shuffle(256, seed=42).batch(batch_size).repeat(-1))\n",
    "    \n",
    "    # Validation set\n",
    "    validation_set_iter = iter(validation_set.batch(batch_size).repeat(-1))\n",
    "    num_validation_iter = validation_set_size // batch_size\n",
    "\n",
    "    # Load the scene\n",
    "    scene = init_scene(scene_name, use_tx_array=True)\n",
    "    scene.radio_material_callable = TrainableMaterials(scene, num_objects=len(scene.objects), embedding_size=30, learn_scattering=False)\n",
    "    \n",
    "    # Place the transmitters\n",
    "    place_transmitter_arrays(scene, [1,2])\n",
    "    \n",
    "    # Instantitate receivers\n",
    "    instantiate_receivers(scene, batch_size)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    scaling_factor = tf.Variable(6e-9, dtype=tf.float32, trainable=False)\n",
    "    \n",
    "    # Setting up tensorboard\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    train_log_dir = os.path.join('../tb_logs/', training_name, current_time)\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "    # Checkpoint\n",
    "    weights_filename = os.path.join('../checkpoints/', training_name)\n",
    "\n",
    "    @tf.function\n",
    "    def training_step(rx_pos, h_meas, traced_paths):\n",
    "    \n",
    "        # Placer receiver\n",
    "        set_receiver_positions(scene, rx_pos)\n",
    "    \n",
    "        # Build traced paths\n",
    "        traced_paths = tensor_dicts_to_traced_paths(scene, traced_paths)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            # Compute paths fields\n",
    "            paths = scene.compute_fields(*traced_paths,\n",
    "                                         scat_random_phases=False,\n",
    "                                         check_scene=False)\n",
    "        \n",
    "            a, tau = paths.cir(scattering=False) # Disable scattering\n",
    "        \n",
    "            # Compute channel frequency response    \n",
    "            h_rt = cir_to_ofdm_channel(frequencies, a, tau)\n",
    "    \n",
    "            # Remove useless dimensions \n",
    "            h_rt = tf.squeeze(h_rt, axis=[0,2,5])\n",
    "    \n",
    "            # Normalize h to make sure that power is independent of the number of subacrriers\n",
    "            h_rt /= tf.complex(tf.sqrt(tf.cast(num_subcarriers, tf.float32)), 0.)\n",
    "    \n",
    "            # Compute scaling factor\n",
    "            scaling_factor.assign(delta*scaling_factor + (1-delta)*mse_power_scaling_factor(h_rt, h_meas))\n",
    "    \n",
    "            # Scale measurements\n",
    "            h_meas *= tf.complex(tf.sqrt(scaling_factor), 0.)\n",
    "    \n",
    "            # Compute losses\n",
    "            h_rt = sionna.utils.flatten_dims(h_rt, 3, 0)\n",
    "            h_meas = sionna.utils.flatten_dims(h_meas, 3, 0)\n",
    "            # Compute the average of a power and delay spread loss\n",
    "            loss_ds = delay_spread_loss(h_rt, h_meas)\n",
    "            loss_pow = power_loss(h_rt, h_meas)\n",
    "            loss_ds_pow = loss_ds + loss_pow\n",
    "\n",
    "        # Use loss_ds_pow for training\n",
    "        grads = tape.gradient(loss_ds_pow, tape.watched_variables(), unconnected_gradients=tf.UnconnectedGradients.ZERO)\n",
    "        optimizer.apply_gradients(zip(grads, tape.watched_variables()))\n",
    "    \n",
    "        return loss_ds_pow, loss_ds, loss_pow, scaling_factor\n",
    "\n",
    "    @tf.function\n",
    "    def evaluation_step(rx_pos, h_meas, traced_paths, scaling_factor):\n",
    "    \n",
    "        # Placer receiver\n",
    "        set_receiver_positions(scene, rx_pos)\n",
    "    \n",
    "        # Build traced paths\n",
    "        traced_paths = tensor_dicts_to_traced_paths(scene, traced_paths)\n",
    "                \n",
    "        paths = scene.compute_fields(*traced_paths,\n",
    "                                     scat_random_phases=False,\n",
    "                                     check_scene=False)\n",
    "    \n",
    "        a, tau = paths.cir(scattering=False) # Disable scattering\n",
    "    \n",
    "        # Compute channel frequency response    \n",
    "        h_rt = cir_to_ofdm_channel(frequencies, a, tau)\n",
    "\n",
    "        # Remove useless dimensions \n",
    "        h_rt = tf.squeeze(h_rt, axis=[0,2,5])\n",
    "\n",
    "        # Normalize h to make sure that power is independent of the number of subacrriers\n",
    "        h_rt /= tf.complex(tf.sqrt(tf.cast(num_subcarriers, tf.float32)), 0.)\n",
    "\n",
    "        # Scale measurements\n",
    "        h_meas *= tf.complex(tf.sqrt(scaling_factor), 0.)\n",
    "\n",
    "        # Compute losses\n",
    "        h_rt = sionna.utils.flatten_dims(h_rt, 3, 0)\n",
    "        h_meas = sionna.utils.flatten_dims(h_meas, 3, 0)\n",
    "        # Compute the average of a power and delay spread loss\n",
    "        loss_ds = delay_spread_loss(h_rt, h_meas)\n",
    "        loss_pow = power_loss(h_rt, h_meas)\n",
    "\n",
    "        return loss_ds, loss_pow\n",
    "\n",
    "    for step in range(num_iterations):\n",
    "    \n",
    "        # Next set of traced paths\n",
    "        next_item = next(training_set_iter, None)\n",
    "        \n",
    "        # Retreive the receiver position separately\n",
    "        rx_pos, h_meas, traced_paths = next_item[0], next_item[1], next_item[2:]\n",
    "        # Skip iteration if does not match the batch size\n",
    "        if rx_pos.shape[0] != batch_size:\n",
    "            continue\n",
    "    \n",
    "        # Batchify\n",
    "        traced_paths = batchify(traced_paths)\n",
    "    \n",
    "        # Train\n",
    "        tr_quantities = training_step(rx_pos, h_meas, traced_paths)\n",
    "        loss_ds_pow, loss_ds, loss_pow, scaling_factor = tr_quantities\n",
    "    \n",
    "        # Logging\n",
    "        if (step % 100) == 0:\n",
    "            with train_summary_writer.as_default():\n",
    "                # Log in TB\n",
    "                tf.summary.scalar('loss_ds_pow_training', loss_ds_pow.numpy(), step=step)\n",
    "                tf.summary.scalar('loss_ds_training', loss_ds.numpy(), step=step)\n",
    "                tf.summary.scalar('loss_pow_training', loss_pow.numpy(), step=step)\n",
    "                tf.summary.scalar('scaling_factor', scaling_factor.numpy(), step=step)\n",
    "                # Save model\n",
    "                save_model(scene.radio_material_callable, weights_filename, scaling_factor=scaling_factor.numpy())\n",
    "        \n",
    "        # Evaluate periodically on the evaluation set\n",
    "        if ((step+1) % 1000) == 0:\n",
    "            eval_loss_ds = 0.0\n",
    "            eval_loss_pow = 0.0\n",
    "            for _ in range(num_validation_iter):\n",
    "                # Next set of traced paths\n",
    "                next_item = next(validation_set_iter, None)\n",
    "                \n",
    "                # Retreive the receiver position separately\n",
    "                rx_pos, h_meas, traced_paths = next_item[0], next_item[1], next_item[2:]\n",
    "                # Skip iteration if does not match the batch size\n",
    "                if rx_pos.shape[0] != batch_size:\n",
    "                    continue\n",
    "            \n",
    "                # Batchify\n",
    "                traced_paths = batchify(traced_paths)\n",
    "            \n",
    "                # Train\n",
    "                eval_quantities = evaluation_step(rx_pos, h_meas, traced_paths, scaling_factor)\n",
    "                loss_ds, loss_pow = eval_quantities\n",
    "                eval_loss_ds += loss_ds\n",
    "                eval_loss_pow += loss_pow\n",
    "            eval_loss_ds /= float(num_validation_iter)\n",
    "            eval_loss_pow /= float(num_validation_iter)\n",
    "            # Log in TB\n",
    "            with train_summary_writer.as_default():\n",
    "                tf.summary.scalar('loss_ds_evaluation', eval_loss_ds, step=step)\n",
    "                tf.summary.scalar('loss_pow_evaluation', eval_loss_pow, step=step) \n",
    "    \n",
    "    # Save model\n",
    "    save_model(scene.radio_material_callable, weights_filename, scaling_factor=scaling_factor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29b733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
